{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ⚙️ Install Libraries and Download Dataset"
      ],
      "metadata": {
        "id": "uXCI2uPA8_Hh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muzOZf9s84oI"
      },
      "outputs": [],
      "source": [
        "!pip install simplet5 tqdm  tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test T5\n"
      ],
      "metadata": {
        "id": "9AJmVT8r9Nwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from simplet5 import SimpleT5\n",
        "\n",
        "model = SimpleT5()\n",
        "model.load_model(\"t5\", \"Suppi123/T5-Base-Text-Style-Transfer-Using-Examples\", use_gpu=True)\n",
        "\n",
        "input_text = \"A person stands on the edge of a cliff, contemplating a difficult decision.\"\n",
        "example1 = \"Lmao exactly\"\n",
        "example2 = \"I slipped on the ice and fell my thumb landed in my butt\"\n",
        "example3 = \"Majority of retail investors are in spy calls\"\n",
        "samples = [example1, example2, example3]\n",
        "\n",
        "prompt = 'Here a example sentences: '\n",
        "for sample in samples:\n",
        "  prompt += '{' + sample + '} '\n",
        "prompt += 'Here is a sentence: {' + input_text + '} '\n",
        "prompt += 'Here is a rewrite of this sentence according to the example sentences: {'\n",
        "\n",
        "output_text = model.predict(source_text=prompt, repetition_penalty=1.0,\n",
        "                                    num_return_sequences=1, num_beams=5)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWUU7V9R9QX9",
        "outputId": "b09f0b0d-5779-46f2-de2b-d4c984feee39"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A man standing on the edge of a cliff contemplating suicide.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Flan-T5"
      ],
      "metadata": {
        "id": "R0BMDMx7Ad-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from simplet5 import SimpleT5\n",
        "\n",
        "model = SimpleT5()\n",
        "model.load_model(\"t5\", \"Suppi123/Flan-T5-Base-Text-Style-Transfer-Using-Examples\", use_gpu=True)\n",
        "\n",
        "input_text = \"A person stands on the edge of a cliff, contemplating a difficult decision.\"\n",
        "example1 = \"Lmao exactly\"\n",
        "example2 = \"I slipped on the ice and fell my thumb landed in my butt\"\n",
        "example3 = \"Majority of retail investors are in spy calls\"\n",
        "samples = [example1, example2, example3]\n",
        "\n",
        "prompt = 'Here a example sentences: '\n",
        "for sample in samples:\n",
        "  prompt += '{' + sample + '} '\n",
        "prompt += 'Here is a sentence: {' + input_text + '} '\n",
        "prompt += 'Here is a rewrite of this sentence according to the example sentences: {'\n",
        "\n",
        "output_text = model.predict(source_text=prompt, repetition_penalty=1.0,\n",
        "                                    num_return_sequences=1, num_beams=5)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqqW0VMCAg_1",
        "outputId": "63008192-0ced-48c5-b0ba-84084161565b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a man stands on the edge of a cliff contemplating a dangerous decision']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test BART"
      ],
      "metadata": {
        "id": "l8aNqYGLBXR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "input_text = \"A person stands on the edge of a cliff, contemplating a difficult decision.\"\n",
        "example1 = \"Lmao exactly\"\n",
        "example2 = \"I slipped on the ice and fell my thumb landed in my butt\"\n",
        "example3 = \"Majority of retail investors are in spy calls\"\n",
        "samples = [example1, example2, example3]\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "sep_token = tokenizer.sep_token\n",
        "bos_token = tokenizer.bos_token\n",
        "eos_token = tokenizer.eos_token\n",
        "\n",
        "prompt = \"\"\n",
        "for sample in samples:\n",
        "  prompt += bos_token + sample + sep_token\n",
        "prompt += bos_token + input_text + eos_token\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained('Suppi123/Bart-Base-Text-Style-Transfer-Using-Examples').to(device)\n",
        "\n",
        "input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "output_ids = model.generate(input_ids, max_length=512, num_beams=5, early_stopping=True)\n",
        "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "print(output_text)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg8EFRl2BbKh",
        "outputId": "5d56724b-d725-4dca-aead-77780f3ae166"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A guy stands on edge of a cliff contemplating suicide\n"
          ]
        }
      ]
    }
  ]
}